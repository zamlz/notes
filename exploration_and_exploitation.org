#+TITLE: Exploration and Exploitation
#+AUTHOR: Amlesh Sivanantham (zamlz)
#+ROAM_ALIAS:
#+ROAM_TAGS:
#+CREATED: [2021-04-03 Sat 22:09]
#+LAST_MODIFIED: [2021-04-03 Sat 22:11:55]

A fundamental problem in [[file:reinforcement_learning.org][Reinforcement Learning]] is whether to leverage exploration in order to find new strategies or states with better [[file:reward_signal.org][Reward]], or to exploit existing knowledge of strategies and states to get existing [[file:reward_signal.org][Reward Signal]]. How do we leverage new and existing experiences to safely explore the environment in order to gain new (better) reward?
